{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install geopy dash dash-bootstrap-components\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from geopy.distance import geodesic\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "# origem dos dados\n",
        "\n",
        "corridas_df = pd.read_csv(\"ride_v2.csv\", sep=\";\", dtype=str)\n",
        "enderecos_df = pd.read_csv(\"rideaddress_v1.csv\", sep=\";\", dtype=str)\n",
        "estimativas_df = pd.read_csv(\"rideestimative_v3.csv\", sep=\";\", dtype=str)\n",
        "produtos_df = pd.read_csv(\"product.csv\", sep=\";\", dtype=str)\n",
        "\n",
        "# padronização dos dados\n",
        "\n",
        "corridas_df[\"Schedule\"] = pd.to_datetime(corridas_df[\"Schedule\"], errors=\"coerce\")\n",
        "for df in [corridas_df, enderecos_df, estimativas_df]:\n",
        "    df[\"RideID\"] = df[\"RideID\"].astype(str).str.replace(\".0\", \"\", regex=False)\n",
        "\n",
        "# colunas derivadas\n",
        "\n",
        "corridas_df[\"DiaSemana\"] = corridas_df[\"Schedule\"].dt.weekday\n",
        "corridas_df[\"HoraDia\"] = corridas_df[\"Schedule\"].dt.hour\n",
        "corridas_df[\"Minuto\"] = corridas_df[\"Schedule\"].dt.minute\n",
        "corridas_df[\"HoraDecimal\"] = corridas_df[\"HoraDia\"] + corridas_df[\"Minuto\"] / 60\n",
        "corridas_df[\"Janela15\"] = corridas_df[\"Schedule\"].dt.floor(\"15min\")\n",
        "tempo_df = corridas_df[[\"RideID\", \"DiaSemana\", \"HoraDia\", \"Minuto\", \"HoraDecimal\", \"Janela15\"]].dropna()\n",
        "\n",
        "# usa as coord, de origem e destinos\n",
        "\n",
        "enderecos_df = enderecos_df.rename(columns={\"RideAddressTypeID\": \"TipoEndereco\"})\n",
        "origem_df = enderecos_df[enderecos_df[\"TipoEndereco\"] == \"1\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(columns={\"Lat\": \"LatOrig\", \"Lng\": \"LngOrig\", \"Address\": \"EnderecoOrig\"})\n",
        "destino_df = enderecos_df[enderecos_df[\"TipoEndereco\"] == \"2\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(columns={\"Lat\": \"LatDest\", \"Lng\": \"LngDest\", \"Address\": \"EnderecoDest\"})\n",
        "coordenadas_df = pd.merge(origem_df, destino_df, on=\"RideID\", how=\"inner\")\n",
        "\n",
        "for col in [\"LatOrig\", \"LngOrig\", \"LatDest\", \"LngDest\"]:\n",
        "    coordenadas_df[col] = coordenadas_df[col].str.replace(\",\", \".\").astype(float).round(6)\n",
        "\n",
        "#junta estimativa e produtoss\n",
        "\n",
        "estimativas_df[\"ProductID\"] = estimativas_df[\"ProductID\"].astype(str)\n",
        "produtos_df[\"ProductID\"] = produtos_df[\"ProductID\"].astype(str)\n",
        "estimativas_merge = pd.merge(estimativas_df, produtos_df, on=\"ProductID\", how=\"left\")\n",
        "estimativas_merge[\"Price\"] = estimativas_merge[\"Price\"].str.replace(\",\", \".\").astype(float)\n",
        "\n",
        "dicionario_estimativas = estimativas_merge.groupby(\"RideID\").apply(\n",
        "    lambda x: dict(zip(x[\"Description\"], x[\"Price\"]))\n",
        ").reset_index().rename(columns={0: \"Estimativas\"})\n",
        "\n",
        "# filtragem de IDs\n",
        "\n",
        "coordenadas_df[\"RideID\"] = coordenadas_df[\"RideID\"].astype(str)\n",
        "dicionario_estimativas[\"RideID\"] = dicionario_estimativas[\"RideID\"].astype(str)\n",
        "ride_ids_validos = set(tempo_df[\"RideID\"]) & set(coordenadas_df[\"RideID\"]) & set(dicionario_estimativas[\"RideID\"])\n",
        "\n",
        "tempo_df = tempo_df[tempo_df[\"RideID\"].isin(ride_ids_validos)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "coordenadas_df = coordenadas_df[coordenadas_df[\"RideID\"].isin(ride_ids_validos)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "dicionario_estimativas = dicionario_estimativas[dicionario_estimativas[\"RideID\"].isin(ride_ids_validos)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "\n",
        "# concatenação dos dataframes\n",
        "base_modelo_df = pd.concat([\n",
        "    tempo_df,\n",
        "    coordenadas_df.drop(columns=[\"RideID\"]),\n",
        "    dicionario_estimativas.drop(columns=[\"RideID\"])\n",
        "], axis=1)\n",
        "\n",
        "# calculo da distancia\n",
        "base_modelo_df = base_modelo_df.dropna(subset=[\"LatOrig\", \"LngOrig\", \"LatDest\", \"LngDest\"]).reset_index(drop=True)\n",
        "base_modelo_df[\"DistanciaKM\"] = base_modelo_df.apply(\n",
        "    lambda row: geodesic((row[\"LatOrig\"], row[\"LngOrig\"]), (row[\"LatDest\"], row[\"LngDest\"])).kilometers,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"\\nBase pronta para modelagem:\")\n",
        "print(base_modelo_df.head())\n",
        "\n",
        "# o que vai modelar ()\n",
        "servicos_para_modelar = [\"UberX\", \"99POP\", \"Taxi\"]\n",
        "\n",
        "# modelos de teste\n",
        "resultados_finais = []\n",
        "\n",
        "for servico in servicos_para_modelar:\n",
        "    print(f\"\\Modelo para: {servico}\")\n",
        "    dados_servico = base_modelo_df[base_modelo_df[\"Estimativas\"].apply(\n",
        "        lambda est: isinstance(est, dict) and servico in est and isinstance(est[servico], (int, float))\n",
        "    )].copy()\n",
        "\n",
        "    dados_servico[\"PrecoAlvo\"] = dados_servico[\"Estimativas\"].apply(lambda est: est[servico])\n",
        "\n",
        "    q1 = dados_servico[\"PrecoAlvo\"].quantile(0.25) ###### Remoção de outliers\n",
        "    q3 = dados_servico[\"PrecoAlvo\"].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    limite_inferior = q1 - 1.5 * iqr\n",
        "    limite_superior = q3 + 1.5 * iqr\n",
        "    dados_servico = dados_servico[(dados_servico[\"PrecoAlvo\"] >= limite_inferior) & (dados_servico[\"PrecoAlvo\"] <= limite_superior)]\n",
        "\n",
        "    colunas_basicas = [\"DistanciaKM\", \"DiaSemana\", \"HoraDia\", \"HoraDecimal\", \"LatOrig\", \"LngOrig\", \"LatDest\", \"LngDest\"]\n",
        "\n",
        "    outros_servicos = set()\n",
        "    dados_servico[\"Estimativas\"].apply(lambda est: outros_servicos.update(est.keys()) if isinstance(est, dict) else None)\n",
        "    outros_servicos.discard(servico)\n",
        "\n",
        "    for s in outros_servicos:\n",
        "        nome_col = f\"preco_{s.lower().replace(' ', '_')}\"\n",
        "        dados_servico[nome_col] = dados_servico[\"Estimativas\"].apply(lambda est: est.get(s) if isinstance(est, dict) else np.nan)\n",
        "\n",
        "    # contrução do modelo\n",
        "\n",
        "    colunas_entrada = colunas_basicas + [col for col in dados_servico.columns if col.startswith(\"preco_\")]\n",
        "    X = dados_servico[colunas_entrada].fillna(-1)\n",
        "    y = dados_servico[\"PrecoAlvo\"]\n",
        "\n",
        "    X_treino, X_teste, y_treino, y_teste = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    arvore_modelo = DecisionTreeRegressor(random_state=42)\n",
        "    arvore_modelo.fit(X_treino, y_treino)\n",
        "    y_predito = arvore_modelo.predict(X_teste)\n",
        "\n",
        "    # avaliação\n",
        "    mae = mean_absolute_error(y_teste, y_predito)\n",
        "    rmse = np.sqrt(mean_squared_error(y_teste, y_predito))\n",
        "    r2 = r2_score(y_teste, y_predito)\n",
        "\n",
        "    resultados_finais.append({\n",
        "        \"Servico\": servico,\n",
        "        \"Registros\": len(X),\n",
        "        \"MAE\": round(mae, 2),\n",
        "        \"RMSE\": round(rmse, 2),\n",
        "        \"R2\": round(r2, 4)\n",
        "    })\n",
        "\n",
        "    print(f\"Modelo para {servico} avaliado com sucesso!\")\n",
        "    print(f\" → MAE : R${mae:.2f}\")\n",
        "    print(f\" → RMSE: R${rmse:.2f}\")\n",
        "    print(f\" → R²  : {r2:.4f}\")\n",
        "\n",
        "#resumo\n",
        "\n",
        "resumo_df = pd.DataFrame(resultados_finais).sort_values(by=\"R2\", ascending=False)\n",
        "print(\"\\nModelos Finais:\")\n",
        "print(resumo_df.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljLhlRgMvHBt",
        "outputId": "a2227a2d-5394-408d-ba5c-e4df438c21d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: geopy in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: dash in /usr/local/lib/python3.11/dist-packages (3.0.4)\n",
            "Collecting dash-bootstrap-components\n",
            "  Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /usr/local/lib/python3.11/dist-packages (from geopy) (2.0)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.6)\n",
            "Requirement already satisfied: plotly>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from dash) (5.24.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.7.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.13.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.2.0)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly>=5.0.0->dash) (24.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2025.4.26)\n",
            "Requirement already satisfied: six>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from retrying->dash) (1.17.0)\n",
            "Downloading dash_bootstrap_components-2.0.2-py3-none-any.whl (202 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dash-bootstrap-components\n",
            "Successfully installed dash-bootstrap-components-2.0.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-2676a076380c>:50: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  dicionario_estimativas = estimativas_merge.groupby(\"RideID\").apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Base pronta para modelagem:\n",
            "    RideID  DiaSemana  HoraDia  Minuto  HoraDecimal            Janela15  \\\n",
            "0  1183200          1       10       9    10.150000 2021-08-17 10:00:00   \n",
            "1  1183201          1       10       9    10.150000 2021-08-17 10:00:00   \n",
            "2  1183202          1       10      10    10.166667 2021-08-17 10:00:00   \n",
            "3  1183203          1       10      10    10.166667 2021-08-17 10:00:00   \n",
            "4  1183204          1       10      10    10.166667 2021-08-17 10:00:00   \n",
            "\n",
            "     LatOrig    LngOrig                                       EnderecoOrig  \\\n",
            "0 -26.329754 -48.840428  Rua João Pinheiro, 585 - Rua João Pinheiro - B...   \n",
            "1 -27.491979 -48.528288  Rodovia Rafael da Rocha Pires, 1883 - Rodovia ...   \n",
            "2 -19.849580 -44.019916  Rua Barão do Rio Branco, 12 - Rua Barão do Rio...   \n",
            "3 -23.962423 -46.254658               Tv. Duzentos e Sessenta e Um, 72, 72   \n",
            "4 -10.919802 -37.077442        Rua Argentina, 160 - Rua Argentina - Brasil   \n",
            "\n",
            "     LatDest    LngDest                                       EnderecoDest  \\\n",
            "0 -26.255466 -48.643420  Av. Dr. Nereu Ramos, 450 - Rocio Grande, São F...   \n",
            "1 -27.437149 -48.398243  Angeloni Ingleses (Florianópolis) - Supermerca...   \n",
            "2 -19.936899 -43.940160  R. Antônio de Albuquerque, 1080 - Funcionários...   \n",
            "3 -23.837307 -46.132172                 Semar Supermercados Bertioga, 2141   \n",
            "4 -10.907129 -37.087719  R. Simeão Aguiar, 430 - Novo Paraíso, Aracaju ...   \n",
            "\n",
            "                                         Estimativas  DistanciaKM  \n",
            "0  {'Flash': 89.0, 'UberX': 89.0, 'Comfort': 116....    21.327034  \n",
            "1  {'Flash': 31.5, 'Comfort': 33.5, '99POUPA': 26...    14.217724  \n",
            "2  {'Moto': 25.5, 'Comfort': 44.0, 'UberFlash': 4...    12.774740  \n",
            "3  {'Flash': 47.5, '99POP': 63.69, 'Comfort': 68....    18.644013  \n",
            "4  {'99POUPA': 7.88, '99POP': 7.88, '99TAXI': 17....     1.796461  \n",
            "\\Modelo para: UberX\n",
            "Modelo para UberX avaliado com sucesso!\n",
            " → MAE : R$0.40\n",
            " → RMSE: R$1.66\n",
            " → R²  : 0.9852\n",
            "\\Modelo para: 99POP\n",
            "Modelo para 99POP avaliado com sucesso!\n",
            " → MAE : R$2.54\n",
            " → RMSE: R$6.09\n",
            " → R²  : 0.8599\n",
            "\\Modelo para: Taxi\n",
            "Modelo para Taxi avaliado com sucesso!\n",
            " → MAE : R$2.35\n",
            " → RMSE: R$4.78\n",
            " → R²  : 0.9550\n",
            "\n",
            "Modelos Finais:\n",
            "Servico  Registros  MAE  RMSE     R2\n",
            "  UberX     223721 0.40  1.66 0.9852\n",
            "   Taxi      18926 2.35  4.78 0.9550\n",
            "  99POP     221602 2.54  6.09 0.8599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "from dash import Dash, dcc, html, Input, Output\n",
        "import dash_bootstrap_components as dbc\n",
        "\n",
        "# app Dash\n",
        "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H2(\"Dashboard - Análise de Preços por Serviço\"),\n",
        "    dcc.Dropdown(\n",
        "        id=\"dropdown-servico\",\n",
        "        options=[{\"label\": s, \"value\": s} for s in [\"UberX\", \"99POP\", \"Taxi\"]],\n",
        "        value=\"UberX\",\n",
        "        style={\"width\": \"300px\"}\n",
        "    ),\n",
        "    html.Div([\n",
        "        dcc.Graph(id=\"grafico-dia\"),\n",
        "        dcc.Graph(id=\"grafico-distancia\"),\n",
        "        dcc.Graph(id=\"grafico-previsao\")\n",
        "    ])\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    [Output(\"grafico-dia\", \"figure\"),\n",
        "     Output(\"grafico-distancia\", \"figure\"),\n",
        "     Output(\"grafico-previsao\", \"figure\")],\n",
        "    [Input(\"dropdown-servico\", \"value\")]\n",
        ")\n",
        "def atualizar_graficos(servico):\n",
        "    df = base_modelo_df[base_modelo_df[\"Estimativas\"].apply(lambda est: isinstance(est, dict) and servico in est)].copy()\n",
        "    df[\"Preco\"] = df[\"Estimativas\"].apply(lambda est: est[servico])\n",
        "\n",
        "    # 1. Preço médio por dia da semana\n",
        "    fig1 = px.bar(\n",
        "        df.groupby(\"DiaSemana\")[\"Preco\"].mean().reset_index(),\n",
        "        x=\"DiaSemana\", y=\"Preco\", title=\"Preço médio por dia da semana\"\n",
        "    )\n",
        "\n",
        "    # 2. Preço vs Distância\n",
        "    fig2 = px.scatter(\n",
        "        df, x=\"DistanciaKM\", y=\"Preco\", title=\"Preço vs Distância\",\n",
        "        trendline=\"ols\", opacity=0.6\n",
        "    )\n",
        "\n",
        "    # 3. Preço real vs preço previsto (aqui usamos HoraDecimal como base para o eixo X)\n",
        "    fig3 = px.scatter(\n",
        "        df, x=\"HoraDecimal\", y=\"Preco\", title=\"Preço real vs Hora do Dia\",\n",
        "        opacity=0.6\n",
        "    )\n",
        "\n",
        "    return fig1, fig2, fig3\n",
        "\n",
        "# Executar o servidor Dash\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "id": "r4EOGt3eKPFp",
        "outputId": "64f6e653-a922-42ea-e473-26fb856e01e7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}