{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d_dxL13r2S6u",
        "outputId": "7040ce3a-f4bf-4e03-c9d9-d534e59dd44f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Carregando arquivos...\n",
            "\n",
            "üîß Pr√©-processamento dos dados...\n",
            "\n",
            "üìç Processando coordenadas...\n",
            "\n",
            "üí∞ Processando estimativas de pre√ßo...\n",
            "\n",
            "üß© Criando dataframe final...\n",
            "\n",
            "ü§ñ Treinando modelos de previs√£o...\n",
            "\n",
            "üîÆ Processando servi√ßo: UberX\n",
            "‚úÖ Modelo treinado com 235601 registros\n",
            "MAE: R$0.48 | RMSE: R$2.27 | R¬≤: 0.9904\n",
            "\n",
            "üîÆ Processando servi√ßo: Comfort\n",
            "‚úÖ Modelo treinado com 192876 registros\n",
            "MAE: R$2.20 | RMSE: R$4.88 | R¬≤: 0.9807\n",
            "\n",
            "üîÆ Processando servi√ßo: Black\n",
            "‚úÖ Modelo treinado com 123666 registros\n",
            "MAE: R$1.83 | RMSE: R$4.85 | R¬≤: 0.9852\n",
            "\n",
            "üìä RESUMO DOS MODELOS TREINADOS\n",
            "Servi√ßo  Registros  MAE  RMSE     R¬≤\n",
            "  UberX     235601 0.48  2.27 0.9904\n",
            "  Black     123666 1.83  4.85 0.9852\n",
            "Comfort     192876 2.20  4.88 0.9807\n"
          ]
        }
      ],
      "source": [
        "from geopy.distance import geodesic\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================\n",
        "# 1. CARREGAMENTO DOS ARQUIVOS\n",
        "# =============================================\n",
        "\n",
        "print(\"üì¶ Carregando arquivos...\")\n",
        "\n",
        "# Carregar com delimitador ponto-e-v√≠rgula e tratamento de tipos\n",
        "dfRide = pd.read_csv(\"ride_v2.csv\", sep=\";\", dtype=str)\n",
        "dfRideAdd = pd.read_csv(\"rideaddress_v1.csv\", sep=\";\", dtype=str)\n",
        "dfRideEst = pd.read_csv(\"rideestimative_v3.csv\", sep=\";\", dtype=str)\n",
        "dfProduct = pd.read_csv(\"product.csv\", sep=\";\", dtype=str)\n",
        "\n",
        "# =============================================\n",
        "# 2. PR√â-PROCESSAMENTO DOS DADOS\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nüîß Pr√©-processamento dos dados...\")\n",
        "\n",
        "# Uniformiza√ß√£o de RideID\n",
        "for df in [dfRide, dfRideAdd, dfRideEst]:\n",
        "    df[\"RideID\"] = df[\"RideID\"].astype(str).str.replace(\".0\", \"\", regex=False)\n",
        "\n",
        "# Processamento de datas\n",
        "dfRide[\"Schedule\"] = pd.to_datetime(dfRide[\"Schedule\"], errors=\"coerce\")\n",
        "dfRide = dfRide.dropna(subset=[\"Schedule\"])\n",
        "\n",
        "# Derivar colunas de tempo\n",
        "dfRide[\"Dia\"] = dfRide[\"Schedule\"].dt.weekday\n",
        "dfRide[\"Hora\"] = dfRide[\"Schedule\"].dt.hour\n",
        "dfRide[\"Minuto\"] = dfRide[\"Schedule\"].dt.minute\n",
        "dfRide[\"HoraDecimal\"] = dfRide[\"Hora\"] + dfRide[\"Minuto\"] / 60\n",
        "dfRide[\"Faixa15min\"] = dfRide[\"Schedule\"].dt.floor(\"15min\")\n",
        "\n",
        "# =============================================\n",
        "# 3. PROCESSAMENTO DE COORDENADAS\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nüìç Processando coordenadas...\")\n",
        "\n",
        "# Extrair origem e destino\n",
        "dfRideAdd = dfRideAdd.rename(columns={\"RideAddressTypeID\": \"OrigDest\"})\n",
        "dfOrigem = dfRideAdd[dfRideAdd[\"OrigDest\"] == \"1\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(\n",
        "    columns={\"Lat\": \"Lat1\", \"Lng\": \"Lng1\", \"Address\": \"AddressOrig\"}\n",
        ")\n",
        "dfDestino = dfRideAdd[dfRideAdd[\"OrigDest\"] == \"2\"][[\"RideID\", \"Lat\", \"Lng\", \"Address\"]].rename(\n",
        "    columns={\"Lat\": \"Lat2\", \"Lng\": \"Lng2\", \"Address\": \"AddressDest\"}\n",
        ")\n",
        "\n",
        "# Merge de coordenadas\n",
        "dfCoords = pd.merge(dfOrigem, dfDestino, on=\"RideID\", how=\"inner\")\n",
        "\n",
        "# Corrigir formato num√©rico\n",
        "for col in [\"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]:\n",
        "    dfCoords[col] = dfCoords[col].str.replace(\",\", \".\").astype(float).round(6)\n",
        "\n",
        "# =============================================\n",
        "# 4. INTEGRA√á√ÉO DAS ESTIMATIVAS\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nüí∞ Processando estimativas de pre√ßo...\")\n",
        "\n",
        "# Merge com produtos\n",
        "dfRideEst[\"ProductID\"] = dfRideEst[\"ProductID\"].astype(str)\n",
        "dfProduct[\"ProductID\"] = dfProduct[\"ProductID\"].astype(str)\n",
        "\n",
        "dfEstimadaComProduto = pd.merge(dfRideEst, dfProduct, on=\"ProductID\", how=\"left\")\n",
        "dfEstimadaComProduto[\"Price\"] = dfEstimadaComProduto[\"Price\"].str.replace(\",\", \".\").astype(float)\n",
        "\n",
        "# Criar dicion√°rio de estimativas\n",
        "dfEstimadaSelecionada = dfEstimadaComProduto.groupby(\"RideID\").apply(\n",
        "    lambda x: dict(zip(x[\"Description\"], x[\"Price\"]))\n",
        ").reset_index().rename(columns={0: \"Estimativas\"})\n",
        "\n",
        "# =============================================\n",
        "# 5. CRIA√á√ÉO DO DATAFRAME FINAL\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nüß© Criando dataframe final...\")\n",
        "\n",
        "# Filtrar por IDs comuns\n",
        "dfTempo = dfRide[[\"RideID\", \"Dia\", \"Hora\", \"Minuto\", \"HoraDecimal\", \"Faixa15min\"]].dropna()\n",
        "ids_comuns = set(dfTempo[\"RideID\"]) & set(dfCoords[\"RideID\"]) & set(dfEstimadaSelecionada[\"RideID\"])\n",
        "\n",
        "dfTempo = dfTempo[dfTempo[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "dfCoords = dfCoords[dfCoords[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "dfEstimadaSelecionada = dfEstimadaSelecionada[dfEstimadaSelecionada[\"RideID\"].isin(ids_comuns)].sort_values(\"RideID\").reset_index(drop=True)\n",
        "\n",
        "# Concatenar horizontalmente\n",
        "dfDerivado = pd.concat([\n",
        "    dfTempo,\n",
        "    dfCoords.drop(columns=[\"RideID\"]),\n",
        "    dfEstimadaSelecionada.drop(columns=[\"RideID\"])\n",
        "], axis=1)\n",
        "\n",
        "# Remover linhas com coordenadas inv√°lidas\n",
        "dfDerivado = dfDerivado.dropna(subset=[\"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]).reset_index(drop=True)\n",
        "\n",
        "# Calcular dist√¢ncia\n",
        "dfDerivado[\"Distancia_km\"] = dfDerivado.apply(\n",
        "    lambda row: geodesic((row[\"Lat1\"], row[\"Lng1\"]), (row[\"Lat2\"], row[\"Lng2\"])).kilometers,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# =============================================\n",
        "# 6. TREINAMENTO DOS MODELOS (SE√á√ÉO CORRIGIDA)\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nü§ñ Treinando modelos de previs√£o...\")\n",
        "\n",
        "# Servi√ßos alvo\n",
        "servicos_alvo = [\"UberX\", \"Comfort\", \"Black\"]\n",
        "\n",
        "# Listas para resultados\n",
        "resultados = []\n",
        "modelos_treinados = {}\n",
        "\n",
        "for servico in servicos_alvo:\n",
        "    print(f\"\\nüîÆ Processando servi√ßo: {servico}\")\n",
        "\n",
        "    # CORRE√á√ÉO: Filtro corrigido para evitar erro de sintaxe\n",
        "    mask = dfDerivado[\"Estimativas\"].apply(\n",
        "        lambda d: isinstance(d, dict) and servico in d and isinstance(d[servico], (int, float))\n",
        "    )\n",
        "    df_modelo = dfDerivado[mask].copy()\n",
        "\n",
        "    if df_modelo.empty:\n",
        "        print(f\"‚ö†Ô∏è Nenhum dado encontrado para {servico}\")\n",
        "        continue\n",
        "\n",
        "    # Definir vari√°vel alvo\n",
        "    df_modelo[\"y\"] = df_modelo[\"Estimativas\"].apply(lambda d: d[servico])\n",
        "\n",
        "    # Features base\n",
        "    features_base = [\"Distancia_km\", \"Dia\", \"Hora\", \"HoraDecimal\", \"Lat1\", \"Lng1\", \"Lat2\", \"Lng2\"]\n",
        "\n",
        "    # Features auxiliares (outros servi√ßos)\n",
        "    servicos_aux = set()\n",
        "    df_modelo[\"Estimativas\"].apply(lambda d: servicos_aux.update(d.keys()) if isinstance(d, dict) else None)\n",
        "    servicos_aux.discard(servico)\n",
        "\n",
        "    for s in servicos_aux:\n",
        "        nome_coluna = f\"aux_{s.lower().replace(' ', '_')}\"\n",
        "        df_modelo[nome_coluna] = df_modelo[\"Estimativas\"].apply(lambda d: d.get(s, np.nan))\n",
        "\n",
        "    # Preparar dados de treino\n",
        "    features_auxiliares = [col for col in df_modelo.columns if col.startswith(\"aux_\")]\n",
        "    X = df_modelo[features_base + features_auxiliares].fillna(-1)\n",
        "    y = df_modelo[\"y\"]\n",
        "\n",
        "    # Verificar tamanho do dataset\n",
        "    if len(X) < 100:\n",
        "        print(f\"‚ö†Ô∏è Dados insuficientes para {servico} ({len(X)} registros)\")\n",
        "        continue\n",
        "\n",
        "    # Dividir em treino e teste\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Treinar modelo\n",
        "    modelo = RandomForestRegressor(random_state=42)\n",
        "    modelo.fit(X_train, y_train)\n",
        "    y_pred = modelo.predict(X_test)\n",
        "\n",
        "    # Armazenar modelo\n",
        "    modelos_treinados[servico] = modelo\n",
        "\n",
        "    # Calcular m√©tricas\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    resultados.append({\n",
        "        \"Servi√ßo\": servico,\n",
        "        \"Registros\": len(X),\n",
        "        \"MAE\": round(mae, 2),\n",
        "        \"RMSE\": round(rmse, 2),\n",
        "        \"R¬≤\": round(r2, 4)\n",
        "    })\n",
        "\n",
        "    print(f\"‚úÖ Modelo treinado com {len(X)} registros\")\n",
        "    print(f\"MAE: R${mae:.2f} | RMSE: R${rmse:.2f} | R¬≤: {r2:.4f}\")\n",
        "\n",
        "# =============================================\n",
        "# 7. RESULTADOS FINAIS\n",
        "# =============================================\n",
        "\n",
        "print(\"\\nüìä RESUMO DOS MODELOS TREINADOS\")\n",
        "if resultados:\n",
        "    df_resultados = pd.DataFrame(resultados).sort_values(by=\"R¬≤\", ascending=False)\n",
        "    print(df_resultados.to_string(index=False))\n",
        "else:\n",
        "    print(\"‚ùå Nenhum modelo foi treinado com sucesso.\")\n",
        "\n",
        "# =============================================\n",
        "# 8. FUN√á√ÉO DE PREVIS√ÉO POR ENDERE√áO\n",
        "# =============================================\n",
        "\n",
        "from geopy.geocoders import Nominatim\n",
        "\n",
        "def prever_por_endereco():\n",
        "    print(\"\\nüìç PREVIS√ÉO POR ENDERE√áO\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "    # Mostrar servi√ßos dispon√≠veis\n",
        "    servicos_disponiveis = list(modelos_treinados.keys())\n",
        "    print(\"Servi√ßos dispon√≠veis:\", \", \".join(servicos_disponiveis))\n",
        "\n",
        "    # Input do usu√°rio\n",
        "    servico = input(\"üëâ Escolha o servi√ßo: \").strip()\n",
        "    if servico not in modelos_treinados:\n",
        "        print(\"‚ùå Servi√ßo n√£o dispon√≠vel\")\n",
        "        return\n",
        "\n",
        "    origem = input(\"üìå Endere√ßo de origem: \")\n",
        "    destino = input(\"üéØ Endere√ßo de destino: \")\n",
        "\n",
        "    # Geocodifica√ß√£o\n",
        "    geolocator = Nominatim(user_agent=\"uber-predict\")\n",
        "\n",
        "    try:\n",
        "        loc_origem = geolocator.geocode(origem)\n",
        "        loc_destino = geolocator.geocode(destino)\n",
        "\n",
        "        if not loc_origem or not loc_destino:\n",
        "            print(\"‚ùå N√£o foi poss√≠vel geocodificar um ou ambos os endere√ßos\")\n",
        "            return\n",
        "\n",
        "        coord_origem = (loc_origem.latitude, loc_origem.longitude)\n",
        "        coord_destino = (loc_destino.latitude, loc_destino.longitude)\n",
        "\n",
        "        distancia = geodesic(coord_origem, coord_destino).kilometers\n",
        "        print(f\"\\nüõ£Ô∏è Dist√¢ncia calculada: {distancia:.2f} km\")\n",
        "\n",
        "        # Preparar dados para previs√£o\n",
        "        agora = pd.Timestamp.now()\n",
        "        dados = {\n",
        "            'Distancia_km': distancia,\n",
        "            'Dia': agora.weekday(),\n",
        "            'Hora': agora.hour,\n",
        "            'HoraDecimal': agora.hour + agora.minute/60,\n",
        "            'Lat1': coord_origem[0],\n",
        "            'Lng1': coord_origem[1],\n",
        "            'Lat2': coord_destino[0],\n",
        "            'Lng2': coord_destino[1]\n",
        "        }\n",
        "\n",
        "        # Preencher features auxiliares\n",
        "        modelo = modelos_treinados[servico]\n",
        "        for feature in modelo.feature_names_in_:\n",
        "            if feature not in dados:\n",
        "                dados[feature] = -1\n",
        "\n",
        "        # Fazer previs√£o\n",
        "        preco = modelo.predict(pd.DataFrame([dados]))[0]\n",
        "        print(f\"\\nüí∞ Pre√ßo estimado para {servico}: R$ {preco:.2f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro durante a previs√£o: {str(e)}\")\n",
        "\n",
        "# Exemplo de uso\n",
        "# prever_por_endereco()"
      ]
    }
  ]
}